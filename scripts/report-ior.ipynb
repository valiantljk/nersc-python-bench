{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"Create or update benchmark results in a NERSC benchmark database.\n",
    "\n",
    "Use this program to record benchmark results in a database at NERSC for report\n",
    "generation later.  There are two modes of execution.  These are single-step\n",
    "\"insert\" mode and two-phase \"initialize/finalize\" mode.\n",
    "\n",
    "Insert mode allows you to record a benchmark result in the database through a\n",
    "single invocation.  This should be needed rarely but having a way to manually \n",
    "insert benchmark results is handy in special cases.\n",
    "\n",
    "Two-phase initialize/finalize mode lets you first reserve a placeholder result\n",
    "slot in the database that you subsequently update with the benchmark outcome.\n",
    "This should be the main usage mode.  You should only use this mode from within\n",
    "a benchmark batch job though.  Invocation in that case is simple because many\n",
    "required entries like job ID, system, or timestamp are included automatically.\n",
    "Here is how the two-phase mode works.  \n",
    "\n",
    "[1] First an initializing invocation is made that records a NULL value for the\n",
    "benchmark result indicating approximately when the benchmark was launched.\n",
    "\n",
    "[2] Ideally the benchmark application runs successfully and a result is\n",
    "extracted, probably from the benchmark's standard output stream.  To finalize\n",
    "the benchmark entry this result is used to replace the original NULL value\n",
    "recorded in the initialization phase.\n",
    "\n",
    "The benchmark may fail to execute for some reason.  It may start up but then\n",
    "crash at a point before a reportable result is extracted from its output.  Most\n",
    "importantly, the benchmark may evan fail to reach such a point before the\n",
    "requested job time limit is reached.  If any such problems occur the finalize\n",
    "step will fail or simply not be executed.  Such failures are represented in the\n",
    "database by the unmodified NULL value.  This logic obviously does not apply to\n",
    "benchmarks underway at any given time.\n",
    "\n",
    "Example:\n",
    "    To simply insert a benchmark result in one go, use the \"insert\" command and\n",
    "    provide the required positional arguments (1) benchmark name, (2) unix\n",
    "    timestamp of the result, (3) job ID, (4) number of tasks, (5) host or\n",
    "    system name, and (6) the metric value itself such as the time in seconds\n",
    "    (default).  For instance::\n",
    "\n",
    "        $ python report-benchmark.py insert \n",
    "            name-of-my-benchmark 1460590909 134151 4800 cori 13.32\n",
    "\n",
    "    Not sure that you have everything set up properly?  Don't worry, you can \n",
    "    prepend the \"--test\" argument before the command (insert) to see what would\n",
    "    happen.  For example, changing the above command we would see::\n",
    "\n",
    "        $ python report-benchmark.py --test insert \n",
    "            name-of-my-benchmark 1460590909 134151 4800 cori 13.32\n",
    "        insert into monitor (bench_name, timestamp, jobid, numtasks, hostname, \n",
    "            metric_value, metric_units, apid) values ('name-of-my-benchmark', \n",
    "            1460590909, '134151', 4800, 'cori', 13.32, 'seconds', 0)\n",
    "        *** TEST MODE *** \n",
    "\n",
    "    Note the \"--test\" argument needs to come before the \"insert.\"\n",
    "\n",
    "Example:\n",
    "    A two-phase initialize/finalize report is carried out in the following way.\n",
    "    The initialize step is just::\n",
    "\n",
    "        python report-benchmark.py initialize\n",
    "\n",
    "    Then the benchmark runs.  Suppose you extract a result and store it in a\n",
    "    shell variable called \"$result.\"  Finalize the benchmark record with this\n",
    "    value like so::\n",
    "\n",
    "        python report-benchmark.py finalize $result\n",
    "\n",
    "    This pair of commands bracketing the benchmark use job environment variables\n",
    "    to do the right thing, making invocations much simpler than the single-shot \n",
    "    mode where we depend entirely on the user for filling in all the report \n",
    "    columns.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('/global/common/cori/software/python/2.7-anaconda/lib/python2.7/site-packages')\n",
    "import  argparse\n",
    "import  os\n",
    "import  sys\n",
    "import  time\n",
    "\n",
    "import  MySQLdb\n",
    "\n",
    "\n",
    "def from_environ(name, test = False):\n",
    "    \"\"\"Return environment variable if defined (placeholder in test mode).\"\"\"\n",
    "    return \"${}\".format(name) if test else os.environ[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Command (object):\n",
    "    \"\"\"Represents an executable SQL command.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def sql(self):\n",
    "        \"\"\"SQL command representation.\"\"\"\n",
    "        try:\n",
    "            return self._sql\n",
    "        except AttributeError:\n",
    "            self._sql = self._define_sql()\n",
    "            return self._sql\n",
    "\n",
    "    def _define_sql(self):\n",
    "        \"\"\"Implement SQL command representation.\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Insert (Command):\n",
    "    \"\"\"Insertion of benchmark result or a placeholder result.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def within_job(cls, test = False):\n",
    "        \"\"\"Construct placeholder benchmark insert using job environment information.\"\"\"\n",
    "        bench_name = from_environ(\"SLURM_JOB_NAME\", test)\n",
    "        timestamp  = int(time.time())\n",
    "        jobid      = from_environ(\"SLURM_JOB_ID\", test)\n",
    "        numtasks   = from_environ(\"SLURM_NTASKS\", test)\n",
    "        hostname   = from_environ(\"NERSC_HOST\", test)\n",
    "        return cls(bench_name, timestamp, jobid, numtasks, hostname, \"NULL\", \"NULL\")\n",
    "\n",
    "    def __init__(self, bench_name, timestamp, jobid, numtasks, hostname, metric_value,seconds, metric_units = \"MB/s\", \n",
    "            apid = 0):\n",
    "        self.bench_name   = bench_name\n",
    "        self.timestamp    = timestamp\n",
    "        self.jobid        = jobid\n",
    "        self.numtasks     = numtasks\n",
    "        self.hostname     = hostname\n",
    "        self.metric_value = metric_value\n",
    "        self.seconds = seconds\n",
    "        self.metric_units = metric_units\n",
    "        self.apid         = apid\n",
    "\n",
    "    def _define_sql(self):\n",
    "        text  = \"insert into monitor \"\n",
    "        text += \"(bench_name, timestamp, jobid, numtasks, hostname, metric_value, seconds, metric_units, apid) \"\n",
    "        text += \"values (\"\n",
    "        text += \"'{}', \".format(str(self.bench_name))\n",
    "        text += \"{}, \".format(str(self.timestamp))\n",
    "        text += \"'{}', \".format(str(self.jobid))\n",
    "        text += \"{}, \".format(str(self.numtasks))\n",
    "        text += \"'{}', \".format(str(self.hostname))\n",
    "        text += \"{}, \".format(str(self.metric_value))\n",
    "        text += \"{}, \".format(str(self.seconds))\n",
    "        text += \"'{}', \".format(str(self.metric_units))\n",
    "        text += \"{})\".format(str(self.apid))\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Update (Command):\n",
    "    \"\"\"Update of existing benchmark result.\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def within_job(cls, metric_value, seconds, test = False):\n",
    "        \"\"\"Construct benchmark update using job information.\"\"\"\n",
    "        jobid = from_environ(\"SLURM_JOB_ID\", test)\n",
    "        return cls(jobid, metric_value,seconds)\n",
    "\n",
    "    def __init__(self, jobid, metric_value, seconds):\n",
    "        self.jobid        = jobid\n",
    "        self.metric_value = metric_value\n",
    "        self.seconds = seconds\n",
    "\n",
    "    def _define_sql(self):\n",
    "        return \"update monitor set metric_value={},seconds={} where jobid='{}'\".format(self.metric_value,self.seconds, self.jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert(args):\n",
    "    \"\"\"Insert fully-defined benchmark result (use this for backfill).\"\"\"\n",
    "    return Insert(args.bench_name, args.timestamp, args.jobid, args.numtasks, args.hostname, args.metric_value,args.seconds)\n",
    "\n",
    "\n",
    "def initialize(args):\n",
    "    \"\"\"Initialize benchmark result with a placeholder.\"\"\"\n",
    "    return Insert.within_job(args.test)\n",
    "\n",
    "\n",
    "def finalize(args):\n",
    "    \"\"\"Finalize benchmark result with a metric value.\"\"\"\n",
    "    return Update.within_job(args.metric_value, args.seconds, args.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    \"\"\"Parse command line arguments and return them.\"\"\"\n",
    "\n",
    "    # Parser with global options and some sub-commands.\n",
    "\n",
    "    parser = argparse.ArgumentParser(description = __doc__, formatter_class = argparse.RawDescriptionHelpFormatter)\n",
    "    parser.add_argument(\"--test\"         , help = \"activate test mode\"  , action = \"store_true\")\n",
    "    parser.add_argument(\"--verbose\", \"-v\", help = \"more detailed output\", action = \"store_true\")\n",
    "    subparsers = parser.add_subparsers()\n",
    "\n",
    "    # Insert sub-command with all positional arguments.\n",
    "\n",
    "    insert_parser = subparsers.add_parser(\"insert\")\n",
    "    insert_parser.add_argument(\"bench_name\"  , help = \"benchmark name\"                        )\n",
    "    insert_parser.add_argument(\"timestamp\"   , help = \"seconds since Unix epoch\", type = int  )\n",
    "    insert_parser.add_argument(\"jobid\"       , help = \"batch job identifier\"                  )\n",
    "    insert_parser.add_argument(\"numtasks\"    , help = \"number of tasks\"         , type = int  )\n",
    "    insert_parser.add_argument(\"hostname\"    , help = \"hostname/system\"                       )\n",
    "    insert_parser.add_argument(\"metric_value\", help = \"write\"            , type = float)\n",
    "    insert_parser.add_argument(\"seconds\", help = \"read\"            , type = float)\n",
    "    insert_parser.set_defaults(func = insert)\n",
    "\n",
    "    # Initialize sub-command where context provides everything.\n",
    "\n",
    "    init_parser = subparsers.add_parser(\"initialize\")\n",
    "    init_parser.set_defaults(func = initialize)\n",
    "\n",
    "    # Finalize sub-command that just takes the metric value.\n",
    "\n",
    "    final_parser = subparsers.add_parser(\"finalize\")\n",
    "    final_parser.add_argument(\"metric_value\", help = \"write\", type = float) # write\n",
    "    final_parser.add_argument(\"seconds\", help = \"read\", type = float) # read\n",
    "    final_parser.set_defaults(func = finalize)\n",
    "\n",
    "    # Parse args, set verbose if test mode, return.\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    if args.test:\n",
    "        args.verbose = True\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def broker_connection(default_file_path = None, db = \"benchmarks\"):\n",
    "    \"\"\"Set up database connection.\"\"\"\n",
    "\n",
    "    if default_file_path is None:\n",
    "        default_file_path = os.path.join(os.environ[ \"HOME\" ], \".mysql\", \".my_staffdb01.cnf\")\n",
    "\n",
    "    return MySQLdb.connect(db = db, read_default_file = default_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    args = parse_arguments()\n",
    "    cmd  = args.func(args)\n",
    "\n",
    "    if args.verbose:\n",
    "        print cmd.sql\n",
    "\n",
    "    if args.test:\n",
    "        print \"*** TEST MODE ***\"\n",
    "        return\n",
    "\n",
    "    connection = broker_connection()\n",
    "    cursor     = connection.cursor()\n",
    "    result     = cursor.execute(cmd.sql)\n",
    "\n",
    "    if args.verbose:\n",
    "        print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--test] [--verbose] {insert,initialize,finalize} ...\n",
      "__main__.py: error: invalid choice: '/global/u1/j/jialin/.local/share/jupyter/runtime/kernel-a87c0a17-0d21-4471-8bd5-e1ec9681dc7e.json' (choose from 'insert', 'initialize', 'finalize')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
