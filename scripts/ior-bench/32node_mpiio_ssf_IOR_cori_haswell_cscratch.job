#!/bin/ksh
#SBATCH -N 32 --ntasks-per-node=32 -t 30 -J 32node_mpiio_ssf -p regular -C haswell --mail-type=FAIL --mail-user=jalnliu@lbl.gov --account=nstaff
SCRDIR=$SCRATCH

. /opt/modules/default/init/ksh
module load lustre-cray_ari_s
module load python/2.7-anaconda
NOST=$(lfs df $SCRDIR | grep OST: | wc -l)  # number of OSTs in file system
if (( $NOST == 0 )) ; then
  echo "Must be run on a Lustre file system. Not $SCRDIR"
  exit
fi
NOST=120
JOBID=${SLURM_JOBID:-$$}
TESTDIR=$SCRDIR/IOR_REGULAR/$SLURM_JOB_NAME/$JOBID
rm -rf $TESTDIR
mkdir -p $TESTDIR || exit
# MULTIPLIER=6
TRANSFER_SIZE=8 # in MiB
STRIPE_SIZE=8   # in MiB
lfs setstripe -s ${STRIPE_SIZE}m -c $NOST $TESTDIR || exit
DATA_TB=4   # total file size in TiB, nodes*memory, 32*128/1024
RPN=32        # ranks per node
NODES=32     # 
RANKS=$(( $NODES * $RPN ))     # fully packed
SEGMENTS=$(( $DATA_TB*1024*1024/$TRANSFER_SIZE/$RANKS ))

OPTIONS="-a MPIIO -c -C -g -b ${TRANSFER_SIZE}m -t ${TRANSFER_SIZE}m -k -H -v -o $TESTDIR/IOR_file"

export IOR_HINT__MPI__romio_cb_read=disable
export IOR_HINT__MPI__romio_cb_write=disable
# export IOR_HINT__MPI__cray_cb_write_lock_mode=1
# export IOR_HINT__MPI__cray_cb_nodes_multiplier=$MULTIPLIER
# export IOR_HINT__MPI__romio_no_indep_rw=true

python report-ior.py initialize 32node_mpiio_ssf_write
python report-ior.py initialize 32node_mpiio_ssf_read

OUT=${SLURM_JOB_NAME}_${RANKS}ranks_${RPN}rpn_${NOST}osts_${NODES}nodes_${JOBID}
srun -n $RANKS --ntasks-per-node $RPN  ../IOR $OPTIONS -w -s $SEGMENTS >> ${OUT}.IOR
python report-ior.py finalize 32node_mpiio_ssf_write $(grep 'Max Write' ${OUT}.IOR | awk '{print $3}' )
srun -n $RANKS --ntasks-per-node $RPN  ../IOR $OPTIONS -r -s $SEGMENTS >> ${OUT}.IOR
python report-ior.py finalize 32node_mpiio_ssf_read $(grep 'Max Read' ${OUT}.IOR | awk '{print $3}' )
rm -rf $TESTDIR
chgrp fbench *
