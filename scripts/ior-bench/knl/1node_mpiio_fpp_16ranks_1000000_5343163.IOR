IOR-3.0.1: MPI Coordinated Test of Parallel I/O

Began: Mon Jun 12 17:47:44 2017
Command line used: /global/cscratch1/sd/fbench/nersc-ior-bench/ior-bench/scripts/ior-bench/knl/../IOR -w -a MPIIO -F -C -g -k -b 1000000 -t 1000000 -s 12884 -o /global/cscratch1/sd/fbench/IOR_REGULAR/1node_mpiio_fpp/5343163/IOR_file -v
Machine: Linux nid09025
Start time skew across all tasks: 0.00 sec

Test 0 started: Mon Jun 12 17:47:44 2017
Path: /global/cscratch1/sd/fbench/IOR_REGULAR/1node_mpiio_fpp/5343163
FS: 27719.5 TiB   Used FS: 63.7%   Inodes: 5955.2 Mi   Used Inodes: 22.9%
Participating tasks: 16
Using reorderTasks '-C' (expecting block, not cyclic, task assignment)
Summary:
	api                = MPIIO (version=3, subversion=1)
	test filename      = /global/cscratch1/sd/fbench/IOR_REGULAR/1node_mpiio_fpp/5343163/IOR_file
	access             = file-per-process, independent
	pattern            = strided (12884 segments)
	ordering in a file = sequential offsets
	ordering inter file= constant task offsets = 1
	clients            = 16 (16 per node)
	repetitions        = 1
	xfersize           = 1000000 bytes
	blocksize          = 1000000 bytes
	aggregate filesize = 191.99 GiB

access    bw(MiB/s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ---------- ---------  --------   --------   --------   --------   ----
write     1421.22    976.56     976.56     0.151671   137.97     0.178227   138.33     0   

Max Write: 1421.22 MiB/sec (1490.26 MB/sec)

Summary of all tests:
Operation   Max(MiB)   Min(MiB)  Mean(MiB)     StdDev    Mean(s) Test# #Tasks tPN reps fPP reord reordoff reordrand seed segcnt blksiz xsize aggsize API RefNum
write        1421.22    1421.22    1421.22       0.00  138.32757 0 16 16 1 1 1 1 0 0 12884 1000000 1000000 206144000000 MPIIO 0

Finished: Mon Jun 12 17:50:03 2017
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

Began: Mon Jun 12 17:50:39 2017
Command line used: /global/cscratch1/sd/fbench/nersc-ior-bench/ior-bench/scripts/ior-bench/knl/../IOR -r -a MPIIO -F -C -g -k -b 1000000 -t 1000000 -s 12884 -o /global/cscratch1/sd/fbench/IOR_REGULAR/1node_mpiio_fpp/5343163/IOR_file -v
Machine: Linux nid09025
Start time skew across all tasks: 0.00 sec

Test 0 started: Mon Jun 12 17:50:39 2017
Path: /global/cscratch1/sd/fbench/IOR_REGULAR/1node_mpiio_fpp/5343163
FS: 27719.5 TiB   Used FS: 63.7%   Inodes: 5955.2 Mi   Used Inodes: 22.9%
Participating tasks: 16
Using reorderTasks '-C' (expecting block, not cyclic, task assignment)
Summary:
	api                = MPIIO (version=3, subversion=1)
	test filename      = /global/cscratch1/sd/fbench/IOR_REGULAR/1node_mpiio_fpp/5343163/IOR_file
	access             = file-per-process, independent
	pattern            = strided (12884 segments)
	ordering in a file = sequential offsets
	ordering inter file= constant task offsets = 1
	clients            = 16 (16 per node)
	repetitions        = 1
	xfersize           = 1000000 bytes
	blocksize          = 1000000 bytes
	aggregate filesize = 191.99 GiB

access    bw(MiB/s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ---------- ---------  --------   --------   --------   --------   ----
read      1360.42    976.56     976.56     0.182775   144.03     0.289516   144.51     0   

Max Read:  1360.42 MiB/sec (1426.50 MB/sec)

Summary of all tests:
Operation   Max(MiB)   Min(MiB)  Mean(MiB)     StdDev    Mean(s) Test# #Tasks tPN reps fPP reord reordoff reordrand seed segcnt blksiz xsize aggsize API RefNum
read         1360.42    1360.42    1360.42       0.00  144.51036 0 16 16 1 1 1 1 0 0 12884 1000000 1000000 206144000000 MPIIO 0

Finished: Mon Jun 12 17:53:04 2017
